{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update PIONEER custom vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio_vocab_dir = Path('/home/jovyan/ohdsi-omop-pioneer/pioneer_custom_vocabulary/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SCHEMA = 'vocab'\n",
    "TEMP_SCHEMA = 'temp_schema'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'postgresql'\n",
    "port = '5432'\n",
    "db = 'ohdsi'\n",
    "engine = create_engine(f'postgresql://{input(\"User:\")}:{getpass.getpass(\"Password:\")}@{server}:{port}/{db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.inspect(engine).get_schema_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load new custom vocab files into a temporary schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    con.execute(f'CREATE SCHEMA {TEMP_SCHEMA};')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom vocab file paths\n",
    "vocabulary_file = pio_vocab_dir/'pioneer_vocabulary.csv'\n",
    "concept_class_file = pio_vocab_dir/'pioneer_concept_class.csv'\n",
    "concept_file = pio_vocab_dir/'pioneer_concepts.csv'\n",
    "\n",
    "# Currently loaded custom vocabulary records as dfs\n",
    "query = f\"SELECT * FROM {VOCAB_SCHEMA}.vocabulary WHERE vocabulary_concept_id = 0\"\n",
    "current_vocab_df = pd.read_sql(sql=query, con=engine)\n",
    "query = f\"SELECT * FROM {VOCAB_SCHEMA}.concept_class WHERE concept_class_concept_id = 0\"\n",
    "current_concept_class_df = pd.read_sql(sql=query, con=engine)\n",
    "query = f\"SELECT * FROM {VOCAB_SCHEMA}.concept WHERE concept_id >= 2000000000\"\n",
    "date_cols = ['valid_start_date', 'valid_end_date']\n",
    "current_concept_df = pd.read_sql(sql=query, con=engine, parse_dates=date_cols)\n",
    "\n",
    "# Read new custom vocab files as dfs\n",
    "vocab_df = pd.read_csv(vocabulary_file, sep=',', dtype=current_vocab_df.dtypes.to_dict())\n",
    "concept_class_df = pd.read_csv(concept_class_file, sep=',', dtype=current_concept_class_df.dtypes.to_dict())\n",
    "dtypes = {k: v for k, v in current_concept_df.dtypes.to_dict().items() if k not in date_cols}\n",
    "concept_df = pd.read_csv(concept_file, sep=',', dtype=dtypes, parse_dates=date_cols)\n",
    "\n",
    "# Load the vocab files into the newly created schema\n",
    "vocab_df.to_sql(name='vocabulary', con=engine, schema=TEMP_SCHEMA, index=False, if_exists='replace')\n",
    "concept_class_df.to_sql(name='concept_class', con=engine, schema=TEMP_SCHEMA, index=False, if_exists='replace')\n",
    "concept_df.to_sql(name='concept', con=engine, schema=TEMP_SCHEMA, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for new custom vocabularies and replace the current ones\n",
    "\n",
    "Each replacement query will be executed as a transaction.  \n",
    "Meaning that if it fails it will automatically do a rollback, otherwise it will be committed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_a_is_subset_of_df_b(a: pd.DataFrame, b: pd.DataFrame) -> bool:\n",
    "    return len(a.merge(b)) == len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records_available = not df_a_is_subset_of_df_b(a=vocab_df, b=current_vocab_df)\n",
    "print(f'New vocabulary table records available: {new_records_available}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_query = f\"\"\"\n",
    "WITH ins1 AS (\n",
    "    INSERT INTO {VOCAB_SCHEMA}.vocabulary\n",
    "    SELECT * FROM {TEMP_SCHEMA}.vocabulary\n",
    ")\n",
    "DELETE FROM {VOCAB_SCHEMA}.vocabulary\n",
    "WHERE vocabulary_concept_id = 0 \n",
    "AND vocabulary_id in \n",
    "    (select vocabulary_id from {TEMP_SCHEMA}.vocabulary);\n",
    "\"\"\"\n",
    "with engine.begin() as con:\n",
    "    con.execute(replace_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concept_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records_available = not df_a_is_subset_of_df_b(a=concept_class_df, b=current_concept_class_df)\n",
    "print(f'New concept_class table records available: {new_records_available}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_query = f\"\"\"\n",
    "WITH ins1 AS (\n",
    "    INSERT INTO {VOCAB_SCHEMA}.concept_class\n",
    "    SELECT * FROM {TEMP_SCHEMA}.concept_class\n",
    ")\n",
    "DELETE FROM {VOCAB_SCHEMA}.concept_class \n",
    "WHERE concept_class_concept_id = 0;\n",
    "\"\"\"\n",
    "with engine.begin() as con:\n",
    "    con.execute(replace_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_records_available = not df_a_is_subset_of_df_b(a=concept_df, b=current_concept_df)\n",
    "print(f'New concept table records available: {new_records_available}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_query = f\"\"\"\n",
    "WITH ins1 AS (\n",
    "    INSERT INTO {VOCAB_SCHEMA}.concept\n",
    "    SELECT * FROM {TEMP_SCHEMA}.concept\n",
    ")\n",
    "DELETE FROM {VOCAB_SCHEMA}.concept\n",
    "WHERE concept_id in \n",
    "    (select concept_id from {TEMP_SCHEMA}.concept);\n",
    "\"\"\"\n",
    "with engine.begin() as con:\n",
    "    con.execute(replace_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the temporary schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "    con.execute(f'DROP SCHEMA {TEMP_SCHEMA} CASCADE;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
